{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcl347/MiniJuypters/blob/main/demo_all_components.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2-dBBGgrTKe"
      },
      "source": [
        "# Medical Code Intelligence — Full Pipeline Demo\n",
        "\n",
        "This notebook demonstrates every component of the Medical Code Intelligence pipeline:\n",
        "\n",
        "| # | Component | Module | GPU? |\n",
        "|---|-----------|--------|------|\n",
        "| 1 | Configuration | `configs.ner_config` | No |\n",
        "| 2 | Shorthand Expansion | `src.clinical.shorthand` | No |\n",
        "| 3 | Negation Detection (rule-based) | `src.clinical.negation` | No |\n",
        "| 4 | ICD-10-CM Code Lookup | `src.clinical.icd_codes` | No |\n",
        "| 5 | MS-DRG Cost Estimation | `src.clinical.drg_costs` | No |\n",
        "| 6 | Entity Post-Processing | `src.inference.entity_utils` | No |\n",
        "| 7 | Evaluation Metrics | `src.evaluation.metrics` | No |\n",
        "| 8 | Curated ICD Dataset Generation | `src.data.icd_dataset` | No |\n",
        "| 9 | MedMentions & MACCROBAT (optional sources) | `src.data.icd_dataset` | No* |\n",
        "| 10 | End-to-End Pipeline | `src.clinical.pipeline` | No** |\n",
        "| 11 | Adversarial Training (overview) | `src.training.adversarial` | Yes |\n",
        "| 12 | Assertion Classifier (transformer) | `src.clinical.assertion` | Optional |\n",
        "\n",
        "\\* MedMentions and MACCROBAT download from HuggingFace on first use; cells show the loader API and structure with graceful fallback if unavailable.\n",
        "\n",
        "\\** The pipeline demo uses `process_with_entities()` (pre-extracted entities), which requires no trained NER model.\n",
        "\n",
        "**All cells run on CPU** without downloading external models (except Section 9, which attempts optional HuggingFace downloads)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jcl347/Medical_Code_Intelligence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehZB-TcNrcbx",
        "outputId": "d9552ed3-8d16-432a-cf05-b86f83d3ef23"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Medical_Code_Intelligence'...\n",
            "remote: Enumerating objects: 232, done.\u001b[K\n",
            "remote: Counting objects: 100% (232/232), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 232 (delta 117), reused 180 (delta 65), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (232/232), 202.09 KiB | 1.58 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGtMBUU1rTKh",
        "outputId": "9be93fd2-2517-4098-f064-34d52f861737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repo root: /content/Medical_Code_Intelligence\n",
            "  configs/ exists: True\n",
            "  src/ exists:     True\n"
          ]
        }
      ],
      "source": [
        "import os, sys, pathlib\n",
        "\n",
        "# Find the repo root by looking for known markers (configs/, src/)\n",
        "# Works whether the notebook runs from notebooks/, the repo root, a cloud\n",
        "# environment (Colab, Kaggle), or elsewhere.\n",
        "def _find_repo_root():\n",
        "    markers = (\"src\", \"configs\")\n",
        "\n",
        "    def _has_markers(p):\n",
        "        return all((p / m).is_dir() for m in markers)\n",
        "\n",
        "    cwd = pathlib.Path.cwd()\n",
        "\n",
        "    # 1. cwd IS the repo root (running from repo root)\n",
        "    if _has_markers(cwd):\n",
        "        return str(cwd)\n",
        "\n",
        "    # 2. cwd is notebooks/ inside the repo\n",
        "    if _has_markers(cwd.parent):\n",
        "        return str(cwd.parent)\n",
        "\n",
        "    # 3. Repo is a subdirectory of cwd (common in Colab: /content/RepoName/)\n",
        "    for child in sorted(cwd.iterdir()):\n",
        "        if child.is_dir() and _has_markers(child):\n",
        "            return str(child)\n",
        "\n",
        "    # 4. Walk up from cwd (handles deeply nested launch dirs)\n",
        "    p = cwd\n",
        "    for _ in range(5):\n",
        "        p = p.parent\n",
        "        if _has_markers(p):\n",
        "            return str(p)\n",
        "\n",
        "    # 5. Last resort: try relative to this file if available\n",
        "    try:\n",
        "        nb_dir = pathlib.Path(__file__).resolve().parent\n",
        "        if _has_markers(nb_dir.parent):\n",
        "            return str(nb_dir.parent)\n",
        "    except NameError:\n",
        "        pass\n",
        "\n",
        "    raise RuntimeError(\n",
        "        f\"Cannot find repo root (looked for src/ + configs/ dirs).\\n\"\n",
        "        f\"  cwd = {cwd}\\n\"\n",
        "        f\"Hint: clone the repo and run from inside it, or set REPO_ROOT manually:\\n\"\n",
        "        f\"  REPO_ROOT = '/path/to/Medical_Code_Intelligence'\"\n",
        "    )\n",
        "\n",
        "REPO_ROOT = _find_repo_root()\n",
        "if REPO_ROOT not in sys.path:\n",
        "    sys.path.insert(0, REPO_ROOT)\n",
        "\n",
        "print(f\"Repo root: {REPO_ROOT}\")\n",
        "print(f\"  configs/ exists: {os.path.isdir(os.path.join(REPO_ROOT, 'configs'))}\")\n",
        "print(f\"  src/ exists:     {os.path.isdir(os.path.join(REPO_ROOT, 'src'))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01fcX57arTKi"
      },
      "source": [
        "---\n",
        "## 1. Configuration — `NERConfig`, `MODEL_CONFIGS`, `DATASET_CONFIGS`\n",
        "\n",
        "All training hyperparameters, model definitions, and dataset metadata live in a single dataclass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C4XVIgorTKi",
        "outputId": "6ac5378c-b90e-4cbd-e882-56b5cfd5caa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Supported Pre-trained Models ===\n",
            "  pubmedbert            microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\n",
            "  biobert               dmis-lab/biobert-v1.1\n",
            "  bio_clinicalbert      emilyalsentzer/Bio_ClinicalBERT\n",
            "  scibert               allenai/scibert_scivocab_uncased\n",
            "  gatortron-base        UFNLP/gatortron-base\n",
            "\n",
            "=== Supported Datasets ===\n",
            "  ncbi_disease          NCBI Disease Corpus - disease name recognition\n",
            "  bc5cdr                BC5CDR - chemical and disease NER from PubMed articles\n",
            "  bc2gm                 BC2GM - gene/protein mention recognition\n",
            "  jnlpba                JNLPBA - biomedical entity recognition (proteins, DNA, RNA, \n",
            "  linnaeus              LINNAEUS - species name recognition\n",
            "  biomedical_ner_all    Combined biomedical NER (10+ entity types across multiple da\n",
            "  icd_ner               ICD-focused composite NER dataset. Combines seven sources wi\n",
            "  biomed_ner            Biomedical NER with 24 entity types including DISORDER, MEDI\n",
            "  icd10_terminology     72,750 ICD-10-CM code/description pairs. Not a token-level N\n",
            "  icd10_code_description  1.4M ICD-10-CM description→code pairs for training code pred\n",
            "  medal                 MeDAL: 14M PubMed abstracts with abbreviation annotations fo\n",
            "  casi                  CASI (Clinical Abbreviation Sense Inventory): 18,164 example\n"
          ]
        }
      ],
      "source": [
        "from configs.ner_config import NERConfig, MODEL_CONFIGS, DATASET_CONFIGS\n",
        "\n",
        "# --- Inspect available models ---\n",
        "print(\"=== Supported Pre-trained Models ===\")\n",
        "for key, cfg in MODEL_CONFIGS.items():\n",
        "    print(f\"  {key:20s}  {cfg['model_name']}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# --- Inspect available datasets ---\n",
        "print(\"=== Supported Datasets ===\")\n",
        "for key, cfg in DATASET_CONFIGS.items():\n",
        "    print(f\"  {key:20s}  {cfg['description'][:60]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xArjK58NrTKj",
        "outputId": "a21a7f2a-91d8-4225-b8d1-e03c26afd1d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Default NERConfig ===\n",
            "  model_key                           = pubmedbert\n",
            "  model_name_or_path                  = microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\n",
            "  dataset_key                         = ncbi_disease\n",
            "  max_seq_length                      = 512\n",
            "  num_train_epochs                    = 20\n",
            "  per_device_train_batch_size         = 16\n",
            "  per_device_eval_batch_size          = 32\n",
            "  learning_rate                       = 5e-05\n",
            "  weight_decay                        = 0.01\n",
            "  warmup_ratio                        = 0.1\n",
            "  max_grad_norm                       = 1.0\n",
            "  lr_scheduler_type                   = linear\n",
            "  fp16                                = True\n",
            "  gradient_accumulation_steps         = 1\n",
            "  early_stopping_patience             = 5\n",
            "  early_stopping_metric               = eval_f1\n",
            "  use_crf                             = False\n",
            "  use_adversarial_training            = False\n",
            "  adv_method                          = fgm\n",
            "  adv_epsilon                         = None\n",
            "  pgd_alpha                           = 0.1\n",
            "  pgd_steps                           = 3\n",
            "  label_smoothing_factor              = 0.0\n",
            "  output_dir                          = outputs\n",
            "  logging_steps                       = 50\n",
            "  eval_steps                          = 200\n",
            "  save_steps                          = 200\n",
            "  save_total_limit                    = 3\n",
            "  seed                                = 42\n",
            "  expand_shorthand                    = True\n",
            "  detect_negation                     = True\n",
            "  negation_scope_window               = 6\n",
            "  resolve_drg                         = False\n",
            "  drg_base_rate                       = 6752.61\n",
            "  use_wandb                           = False\n",
            "  wandb_project                       = medical-ner\n",
            "  experiment_name                     = pubmedbert_ncbi_disease\n"
          ]
        }
      ],
      "source": [
        "# --- Default hyperparameters ---\n",
        "config = NERConfig()\n",
        "print(\"=== Default NERConfig ===\")\n",
        "for k, v in vars(config).items():\n",
        "    print(f\"  {k:35s} = {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU0vHzG5rTKj",
        "outputId": "a03a8dfe-06e5-421e-92dd-952f22bbc579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model:       bio_clinicalbert\n",
            "Dataset:     icd_ner\n",
            "LR:          3e-05\n",
            "Adversarial: fgm (epsilon=None)\n",
            "DRG enabled: True\n"
          ]
        }
      ],
      "source": [
        "# --- Override for a specific experiment ---\n",
        "custom = NERConfig(\n",
        "    model_key=\"bio_clinicalbert\",\n",
        "    dataset_key=\"icd_ner\",\n",
        "    learning_rate=3e-5,\n",
        "    num_train_epochs=15,\n",
        "    use_adversarial_training=True,\n",
        "    adv_method=\"fgm\",\n",
        "    resolve_drg=True,\n",
        ")\n",
        "print(f\"Model:       {custom.model_key}\")\n",
        "print(f\"Dataset:     {custom.dataset_key}\")\n",
        "print(f\"LR:          {custom.learning_rate}\")\n",
        "print(f\"Adversarial: {custom.adv_method} (epsilon={custom.adv_epsilon})\")\n",
        "print(f\"DRG enabled: {custom.resolve_drg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cLjMeqvrTKj"
      },
      "source": [
        "---\n",
        "## 2. Shorthand Expansion — `ShorthandExpander`\n",
        "\n",
        "Expands physician abbreviations (\"cp\" → \"chest pain\") with character offset tracking for NER alignment.\n",
        "\n",
        "Uses the built-in fallback (~280 abbreviations) so no network download is required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMpvKu5BrTKj",
        "outputId": "9d55fa57-a0ae-4a22-82ac-f34e66074d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 246 abbreviations\n",
            "Ambiguous: 0\n"
          ]
        }
      ],
      "source": [
        "from src.clinical.shorthand import ShorthandExpander\n",
        "\n",
        "expander = ShorthandExpander(source=\"builtin\")\n",
        "print(f\"Loaded {expander.num_abbreviations} abbreviations\")\n",
        "print(f\"Ambiguous: {expander.num_ambiguous}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGyxy_ZcrTKk",
        "outputId": "8b009cc9-d18e-4ea6-9c8a-abaab2490737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Shorthand Expansion ===\n",
            "  pt c/o sob and cp                   → prothrombin time complaining of shortness of breath and chest pain\n",
            "  hx of dm2, htn, and cad             → history of type 2 diabetes mellitus, hypertension, and coronary artery disease\n",
            "  dx: afib r/o mi                     → diagnosis: atrial fibrillation rule out myocardial infarction\n",
            "  nkda, aox3, wnl                     → no known drug allergies, aox3, wnl\n"
          ]
        }
      ],
      "source": [
        "# --- Simple expansion ---\n",
        "samples = [\n",
        "    \"pt c/o sob and cp\",\n",
        "    \"hx of dm2, htn, and cad\",\n",
        "    \"dx: afib r/o mi\",\n",
        "    \"nkda, aox3, wnl\",\n",
        "]\n",
        "\n",
        "print(\"=== Shorthand Expansion ===\")\n",
        "for text in samples:\n",
        "    expanded = expander.expand(text)\n",
        "    print(f\"  {text:35s} → {expanded}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOnjnvYCrTKk",
        "outputId": "14afea55-9d64-48a7-bae8-a529fddc6815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  'pt denies cp or sob'\n",
            "Expanded:  'prothrombin time denies chest pain or shortness of breath'\n",
            "\n",
            "Offset map (3 expansions):\n",
            "  'pt' @ [0:2] → 'prothrombin time' @ [0:16]\n",
            "  'cp' @ [10:12] → 'chest pain' @ [24:34]\n",
            "  'sob' @ [16:19] → 'shortness of breath' @ [38:57]\n"
          ]
        }
      ],
      "source": [
        "# --- Expansion with offset tracking ---\n",
        "text = \"pt denies cp or sob\"\n",
        "expanded, offsets = expander.expand_with_offsets(text)\n",
        "print(f\"Original:  {text!r}\")\n",
        "print(f\"Expanded:  {expanded!r}\")\n",
        "print(f\"\\nOffset map ({len(offsets)} expansions):\")\n",
        "for om in offsets:\n",
        "    print(f\"  '{om['abbreviation']}' @ [{om['original_start']}:{om['original_end']}] \"\n",
        "          f\"→ '{om['expansion']}' @ [{om['expanded_start']}:{om['expanded_end']}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flw1F4B5rTKk",
        "outputId": "2e87e204-db99-4ab4-b1eb-c02d58f65435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Identified Abbreviations ===\n",
            "  'pt' @ [0:2] → 'prothrombin time'\n",
            "  'c/o' @ [3:6] → 'complaining of'\n",
            "  'sob' @ [7:10] → 'shortness of breath'\n",
            "  'cp' @ [15:17] → 'chest pain'\n"
          ]
        }
      ],
      "source": [
        "# --- Identify abbreviations without expanding ---\n",
        "abbrevs = expander.identify_abbreviations(\"pt c/o sob and cp on exertion\")\n",
        "print(\"=== Identified Abbreviations ===\")\n",
        "for a in abbrevs:\n",
        "    print(f\"  '{a['abbreviation']}' @ [{a['start']}:{a['end']}] → '{a['expansion']}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LARhYc0rTKl"
      },
      "source": [
        "---\n",
        "## 3. Negation Detection — `NegationDetector`\n",
        "\n",
        "Rule-based ConText/NegEx algorithm with 100+ trigger patterns. Detects six assertion statuses:\n",
        "**AFFIRMED**, **NEGATED**, **POSSIBLE**, **HYPOTHETICAL**, **HISTORICAL**, **FAMILY**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ6PRtxSrTKl",
        "outputId": "4fd5e27f-3f78-43a9-9bc0-bd3893c77648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assertion statuses: ['affirmed', 'negated', 'possible', 'hypothetical', 'historical', 'family']\n"
          ]
        }
      ],
      "source": [
        "from src.clinical.negation import NegationDetector, NegationStatus\n",
        "\n",
        "detector = NegationDetector(scope_window=6)\n",
        "\n",
        "# --- Show all assertion statuses ---\n",
        "print(\"Assertion statuses:\", [s.value for s in NegationStatus])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tLBvR2HrTKl",
        "outputId": "776a0c67-1df8-4baa-f5bf-d34ffd90f1c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'Patient denies chest pain but has persistent cough. No fever. History of diabetes.'\n",
            "\n",
            "Detected 3 negation/context scopes:\n",
            "  [negated     ] trigger='No' scope=[52:60] → 'No fever' (forward)\n",
            "  [negated     ] trigger='denies' scope=[8:26] → 'denies chest pain ' (forward)\n",
            "  [historical  ] trigger='History of' scope=[62:81] → 'History of diabetes' (forward)\n"
          ]
        }
      ],
      "source": [
        "# --- Detect negation scopes in raw text ---\n",
        "text = \"Patient denies chest pain but has persistent cough. No fever. History of diabetes.\"\n",
        "scopes = detector.detect(text)\n",
        "print(f\"Text: {text!r}\\n\")\n",
        "print(f\"Detected {len(scopes)} negation/context scopes:\")\n",
        "for s in scopes:\n",
        "    print(f\"  [{s.status.value:12s}] trigger='{s.trigger_text}' \"\n",
        "          f\"scope=[{s.scope_start}:{s.scope_end}] → '{text[s.scope_start:s.scope_end]}' \"\n",
        "          f\"({s.direction})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qrnXjWUrTKl",
        "outputId": "6db9b374-d8c3-459c-d816-d12a6c9dd829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'Patient denies fever but reports persistent cough. No evidence of pneumonia. Family history of diabetes.'\n",
            "\n",
            "Entity Annotations:\n",
            "  fever           → negated      (trigger: denies)\n",
            "  cough           → affirmed     (trigger: -)\n",
            "  pneumonia       → affirmed     (trigger: -)\n",
            "  diabetes        → affirmed     (trigger: -)\n"
          ]
        }
      ],
      "source": [
        "# --- Annotate pre-extracted entities ---\n",
        "text = \"Patient denies fever but reports persistent cough. No evidence of pneumonia. Family history of diabetes.\"\n",
        "entities = [\n",
        "    {\"text\": \"fever\",     \"label\": \"DIAGNOSIS\", \"start\": 15, \"end\": 20},\n",
        "    {\"text\": \"cough\",     \"label\": \"DIAGNOSIS\", \"start\": 43, \"end\": 48},\n",
        "    {\"text\": \"pneumonia\", \"label\": \"DIAGNOSIS\", \"start\": 67, \"end\": 76},\n",
        "    {\"text\": \"diabetes\",  \"label\": \"DIAGNOSIS\", \"start\": 96, \"end\": 104},\n",
        "]\n",
        "\n",
        "annotated = detector.annotate_entities(text, entities)\n",
        "print(f\"Text: {text!r}\\n\")\n",
        "print(\"Entity Annotations:\")\n",
        "for ent in annotated:\n",
        "    trigger = ent.get('negation_trigger', '-')\n",
        "    print(f\"  {ent['text']:15s} → {ent['negation']:12s} (trigger: {trigger})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_omg1cytrTKl",
        "outputId": "79611815-f899-4021-b0ea-218d2ed481f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'No evidence of pulmonary embolism.' — is 'pulmonary embolism' negated? True\n",
            "'Diagnosed with pulmonary embolism.' — is 'pulmonary embolism' negated? False\n"
          ]
        }
      ],
      "source": [
        "# --- Quick negation check ---\n",
        "text = \"No evidence of pulmonary embolism.\"\n",
        "print(f\"'{text}' — is 'pulmonary embolism' negated? \"\n",
        "      f\"{detector.is_negated(text, 15, 33)}\")\n",
        "\n",
        "text2 = \"Diagnosed with pulmonary embolism.\"\n",
        "print(f\"'{text2}' — is 'pulmonary embolism' negated? \"\n",
        "      f\"{detector.is_negated(text2, 16, 34)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-dFWxY_rTKl",
        "outputId": "9fd794c3-958b-4b62-a9c4-d3455dd2fc08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== All Six Assertion Statuses ===\n",
            "  ✓ affirmed     (expected affirmed    ) — Patient has pneumonia.\n",
            "  ✓ negated      (expected negated     ) — Patient denies chest pain.\n",
            "  ✗ affirmed     (expected possible    ) — Possible diagnosis of lupus.\n",
            "  ✗ affirmed     (expected hypothetical) — If symptoms worsen, consider asthma.\n",
            "  ✓ historical   (expected historical  ) — History of myocardial infarction.\n",
            "  ✓ family       (expected family      ) — Family history of breast cancer.\n"
          ]
        }
      ],
      "source": [
        "# --- Test all six assertion statuses ---\n",
        "test_cases = [\n",
        "    (\"Patient has pneumonia.\", \"pneumonia\", 12, 21, \"affirmed\"),\n",
        "    (\"Patient denies chest pain.\", \"chest pain\", 15, 25, \"negated\"),\n",
        "    (\"Possible diagnosis of lupus.\", \"lupus\", 23, 28, \"possible\"),\n",
        "    (\"If symptoms worsen, consider asthma.\", \"asthma\", 30, 36, \"hypothetical\"),\n",
        "    (\"History of myocardial infarction.\", \"myocardial infarction\", 11, 32, \"historical\"),\n",
        "    (\"Family history of breast cancer.\", \"breast cancer\", 18, 31, \"family\"),\n",
        "]\n",
        "\n",
        "print(\"=== All Six Assertion Statuses ===\")\n",
        "for text, entity, start, end, expected in test_cases:\n",
        "    ents = [{\"text\": entity, \"label\": \"DIAGNOSIS\", \"start\": start, \"end\": end}]\n",
        "    result = detector.annotate_entities(text, ents)\n",
        "    status = result[0][\"negation\"]\n",
        "    match = \"✓\" if status == expected else \"✗\"\n",
        "    print(f\"  {match} {status:12s} (expected {expected:12s}) — {text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHn_Px_DrTKl"
      },
      "source": [
        "---\n",
        "## 4. ICD-10-CM Code Lookup — `ICDCodeLookup`\n",
        "\n",
        "TF-IDF character n-gram matching against 51K ICD-10-CM codes (falls back to 45 built-in codes offline)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "referenced_widgets": [
            "b2bb1af86859472192d2a48dfff41cb2",
            "d447f607fb0e49ec89900f977b203e68",
            "08785f05ee4f478eb209d3082db2ddf1",
            "8f57145a794c4f108d1683773ba283b0",
            "034bc68b896b4c579530bbdae870c761"
          ]
        },
        "id": "2jWdmKGUrTKl",
        "outputId": "ed7fb69d-15fe-4edc-d187-abaacb7d8bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'atta00/icd10-codes' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "ERROR:datasets.load:`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'atta00/icd10-codes' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/613 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2bb1af86859472192d2a48dfff41cb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/577k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d447f607fb0e49ec89900f977b203e68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/test-00000-of-00001.parquet:   0%|          | 0.00/622k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08785f05ee4f478eb209d3082db2ddf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25719 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f57145a794c4f108d1683773ba283b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25719 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "034bc68b896b4c579530bbdae870c761"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 25719 ICD-10-CM codes\n"
          ]
        }
      ],
      "source": [
        "from src.clinical.icd_codes import ICDCodeLookup\n",
        "\n",
        "lookup = ICDCodeLookup()\n",
        "print(f\"Loaded {len(lookup._codes)} ICD-10-CM codes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty0uT5TQrTKl",
        "outputId": "46a51c92-8900-49db-ca94-ba522b6d1104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ICD-10-CM Entity Linking ===\n",
            "  chest pain                     → R07.8: Other chest pain (score=0.949)\n",
            "  type 2 diabetes mellitus       → E11.621: Type 2 diabetes mellitus with foot ulcer (score=0.848)\n",
            "  hypertension                   → H40.05: Ocular hypertension (score=0.821)\n",
            "  congestive heart failure       → I50.89: Other heart failure (score=0.746)\n",
            "  pneumonia                      → J12.89: Other viral pneumonia (score=0.809)\n",
            "  atrial fibrillation            → I48.91: Unspecified atrial fibrillation (score=0.954)\n",
            "  chronic kidney disease         → N18.9: Chronic kidney disease, unspecified (score=0.874)\n"
          ]
        }
      ],
      "source": [
        "# --- Match entity text to ICD codes ---\n",
        "queries = [\n",
        "    \"chest pain\",\n",
        "    \"type 2 diabetes mellitus\",\n",
        "    \"hypertension\",\n",
        "    \"congestive heart failure\",\n",
        "    \"pneumonia\",\n",
        "    \"atrial fibrillation\",\n",
        "    \"chronic kidney disease\",\n",
        "]\n",
        "\n",
        "print(\"=== ICD-10-CM Entity Linking ===\")\n",
        "for query in queries:\n",
        "    matches = lookup.match_entity(query, top_k=3)\n",
        "    top = matches[0] if matches else None\n",
        "    if top:\n",
        "        print(f\"  {query:30s} → {top.code}: {top.description} (score={top.score:.3f})\")\n",
        "    else:\n",
        "        print(f\"  {query:30s} → no match\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0BxITywrTKl",
        "outputId": "2533e558-41b6-4f3b-e03c-9d61f6c8cc57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Direct Code Lookup ===\n",
            "  E11.9: Type 2 diabetes mellitus without complications\n",
            "  I10: not found\n",
            "  J18.9: Pneumonia, unspecified organism\n",
            "  R07.9: Chest pain, unspecified\n",
            "  I50.9: Heart failure, unspecified\n"
          ]
        }
      ],
      "source": [
        "# --- Direct code lookup ---\n",
        "codes_to_look_up = [\"E11.9\", \"I10\", \"J18.9\", \"R07.9\", \"I50.9\"]\n",
        "\n",
        "print(\"=== Direct Code Lookup ===\")\n",
        "for code_str in codes_to_look_up:\n",
        "    code_obj = lookup.lookup_code(code_str)\n",
        "    if code_obj:\n",
        "        print(f\"  {code_obj.code}: {code_obj.description}\")\n",
        "    else:\n",
        "        print(f\"  {code_str}: not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEUyQruGrTKm",
        "outputId": "20463121-edcf-4e02-d2ca-6a8db2248b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Batch Entity → ICD Mapping ===\n",
            "  hypertension         → ['H40.05', 'P29.2', 'K76.6']\n",
            "  pneumonia            → ['J12.89', 'J12.8', 'J15.7']\n",
            "  chest pain           → ['R07.8', 'R07.89', 'R07.9']\n",
            "  diabetes             → ['R73.03', 'E13.61', 'E13.620']\n"
          ]
        }
      ],
      "source": [
        "# --- Batch entity matching ---\n",
        "batch_entities = [\n",
        "    {\"text\": \"hypertension\", \"label\": \"DIAGNOSIS\"},\n",
        "    {\"text\": \"pneumonia\", \"label\": \"DIAGNOSIS\"},\n",
        "    {\"text\": \"chest pain\", \"label\": \"DIAGNOSIS\"},\n",
        "    {\"text\": \"diabetes\", \"label\": \"DIAGNOSIS\"},\n",
        "]\n",
        "\n",
        "results = lookup.match_entities_batch(batch_entities, top_k=3)\n",
        "print(\"=== Batch Entity → ICD Mapping ===\")\n",
        "for r in results:\n",
        "    codes = [c[\"code\"] for c in r.get(\"icd_codes\", [])]\n",
        "    print(f\"  {r['text']:20s} → {codes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qyeVus5rTKm"
      },
      "source": [
        "---\n",
        "## 5. MS-DRG Cost Estimation — `DRGCostEstimator`\n",
        "\n",
        "Maps ICD-10-CM codes to MS-DRGs and estimates financial impact. Uses built-in fallback weights for 32 common DRGs.\n",
        "\n",
        "> **Note:** Full ICD→DRG grouper logic requires `drgpy` (`pip install drgpy`). Without it, only direct DRG code lookups work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6CCKNTMrTKm",
        "outputId": "0b340b41-ec7d-45cd-e2f7-55520726fea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:src.clinical.drg_costs:drgpy not installed (pip install drgpy). DRG grouping unavailable; using weight-table lookup only.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base rate: $6,752.61 (FY 2026)\n",
            "DRG weight table: 32 DRGs loaded\n",
            "Grouper available: False\n"
          ]
        }
      ],
      "source": [
        "from src.clinical.drg_costs import DRGCostEstimator, DRGResult, CostImpactAnalysis\n",
        "\n",
        "estimator = DRGCostEstimator()\n",
        "print(f\"Base rate: ${estimator.base_rate:,.2f} (FY 2026)\")\n",
        "print(f\"DRG weight table: {len(estimator._weights)} DRGs loaded\")\n",
        "print(f\"Grouper available: {estimator._grouper is not None}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUqpZdVkrTKm",
        "outputId": "1b4b1985-ba6d-43d9-e859-f39c2e3d9dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DRG Cost Estimates ===\n",
            "  DRG 291: Heart Failure & Shock W MCC                        wt=1.3968  $  9,432.05  [mcc]\n",
            "  DRG 292: Heart Failure & Shock W CC                         wt=0.9259  $  6,252.24  [cc]\n",
            "  DRG 293: Heart Failure & Shock W/O CC/MCC                   wt=0.6521  $  4,403.38  [base]\n",
            "  DRG 065: Intracranial Hemorrhage Or Cerebral Infarction W CC wt=1.0619  $  7,170.60  [cc]\n",
            "  DRG 066: Intracranial Hemorrhage Or Cerebral Infarction W/O CC/MCC wt=0.7175  $  4,845.00  [base]\n"
          ]
        }
      ],
      "source": [
        "# --- Direct cost estimate by DRG code ---\n",
        "drg_codes = [\"291\", \"292\", \"293\", \"065\", \"066\", \"067\", \"189\", \"190\", \"191\"]\n",
        "\n",
        "print(\"=== DRG Cost Estimates ===\")\n",
        "for code in drg_codes:\n",
        "    result = estimator._build_result(code)\n",
        "    if result:\n",
        "        print(f\"  DRG {result.drg_code}: {result.drg_title:50s} \"\n",
        "              f\"wt={result.relative_weight:.4f}  ${result.estimated_payment:>10,.2f}  [{result.severity_level}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUUMrp2ErTKm",
        "outputId": "a033f21f-fc74-4196-a6a8-c33466f8a31e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ICD → DRG Grouping ===\n",
            "  ['J18.9']                                     → (grouper unavailable — install drgpy)\n",
            "  ['J18.9', 'E11.9']                            → (grouper unavailable — install drgpy)\n",
            "  ['J18.9', 'E11.9', 'N17.9']                   → (grouper unavailable — install drgpy)\n",
            "  ['I50.9']                                     → (grouper unavailable — install drgpy)\n"
          ]
        }
      ],
      "source": [
        "# --- DRG grouping from ICD codes (requires drgpy) ---\n",
        "icd_sets = [\n",
        "    [\"J18.9\"],                         # Pneumonia alone\n",
        "    [\"J18.9\", \"E11.9\"],               # Pneumonia + diabetes\n",
        "    [\"J18.9\", \"E11.9\", \"N17.9\"],     # Pneumonia + diabetes + AKI\n",
        "    [\"I50.9\"],                         # Heart failure\n",
        "]\n",
        "\n",
        "print(\"=== ICD → DRG Grouping ===\")\n",
        "for codes in icd_sets:\n",
        "    result = estimator.get_drg(codes)\n",
        "    if result:\n",
        "        print(f\"  {str(codes):45s} → DRG {result.drg_code}: {result.drg_title} \"\n",
        "              f\"(${result.estimated_payment:,.2f})\")\n",
        "    else:\n",
        "        print(f\"  {str(codes):45s} → (grouper unavailable — install drgpy)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4wHLZEHrTKm",
        "outputId": "4caddcb9-8832-4ffa-f802-13b19a11374c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Heart Failure DRG Family (291/292/293) ===\n",
            "  DRG 291 [mcc ]: wt=1.3968  $  9,432.05  Heart Failure & Shock W MCC\n",
            "  DRG 292 [cc  ]: wt=0.9259  $  6,252.24  Heart Failure & Shock W CC\n",
            "  DRG 293 [base]: wt=0.6521  $  4,403.38  Heart Failure & Shock W/O CC/MCC\n",
            "\n",
            "  Revenue at risk (base→MCC): $5,028.67\n"
          ]
        }
      ],
      "source": [
        "# --- Cost impact analysis (CC/MCC comparison) ---\n",
        "# Even without drgpy, we can demonstrate the analysis structure\n",
        "# by using a known DRG family from the fallback weights\n",
        "\n",
        "# Heart Failure family: DRG 291 (MCC) / 292 (CC) / 293 (base)\n",
        "print(\"=== Heart Failure DRG Family (291/292/293) ===\")\n",
        "for code in [\"291\", \"292\", \"293\"]:\n",
        "    r = estimator._build_result(code)\n",
        "    if r:\n",
        "        print(f\"  DRG {r.drg_code} [{r.severity_level:4s}]: wt={r.relative_weight:.4f}  \"\n",
        "              f\"${r.estimated_payment:>10,.2f}  {r.drg_title}\")\n",
        "\n",
        "# Calculate revenue at risk\n",
        "base = estimator._build_result(\"293\")\n",
        "mcc = estimator._build_result(\"291\")\n",
        "if base and mcc:\n",
        "    gap = mcc.estimated_payment - base.estimated_payment\n",
        "    print(f\"\\n  Revenue at risk (base→MCC): ${gap:,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLTtpgsrrTKm",
        "outputId": "c5409333-d9ec-4c8a-a00b-4e72275f36d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost impact analysis requires drgpy. Install with: pip install drgpy\n"
          ]
        }
      ],
      "source": [
        "# --- Full cost impact analysis via API ---\n",
        "analysis = estimator.analyze_cost_impact([\"J18.9\", \"E11.9\"])\n",
        "if analysis:\n",
        "    print(\"=== Cost Impact Analysis ===\")\n",
        "    d = analysis.to_dict()\n",
        "    print(f\"  Current DRG: {d['current']['drg_code']} — {d['current']['drg_title']}\")\n",
        "    print(f\"  Estimated payment: ${d['current']['estimated_payment']:,.2f}\")\n",
        "    print(f\"  Revenue at risk: ${d['revenue_at_risk']:,.2f}\")\n",
        "    print(f\"  Undercoding risk: {d['undercoding_risk']}\")\n",
        "    if 'mcc_variant' in d:\n",
        "        print(f\"  MCC variant: DRG {d['mcc_variant']['drg_code']} — \"\n",
        "              f\"${d['mcc_variant']['estimated_payment']:,.2f}\")\n",
        "else:\n",
        "    print(\"Cost impact analysis requires drgpy. Install with: pip install drgpy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_XHF9xPrTKm"
      },
      "source": [
        "---\n",
        "## 6. Entity Post-Processing — `post_process_entities()`\n",
        "\n",
        "Filters garbage entities (stopwords, punctuation) and merges adjacent fragments from subword tokenization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RKWrpnfrTKm",
        "outputId": "0e862d12-8f5a-4cd6-a73c-214fcfcad1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before post-processing (5 entities):\n",
            "  'congestive' [DIAGNOSIS] score=0.95\n",
            "  'heart failure' [DIAGNOSIS] score=0.93\n",
            "  'and' [DIAGNOSIS] score=0.30\n",
            "  'type' [DIAGNOSIS] score=0.25\n",
            "  '2 diabetes mellitus' [DIAGNOSIS] score=0.91\n",
            "\n",
            "After post-processing (2 entities):\n",
            "  'congestive heart failure' [DIAGNOSIS] score=0.95\n",
            "  '2 diabetes mellitus' [DIAGNOSIS] score=0.91\n"
          ]
        }
      ],
      "source": [
        "from src.inference.entity_utils import NEREntity, post_process_entities\n",
        "\n",
        "text = \"Patient has congestive heart failure and type 2 diabetes mellitus.\"\n",
        "\n",
        "# Simulate raw NER output with garbage and fragments\n",
        "raw_entities = [\n",
        "    NEREntity(text=\"congestive\",    label=\"DIAGNOSIS\", start_char=12, end_char=22, score=0.95),\n",
        "    NEREntity(text=\"heart failure\", label=\"DIAGNOSIS\", start_char=23, end_char=36, score=0.93),\n",
        "    NEREntity(text=\"and\",           label=\"DIAGNOSIS\", start_char=37, end_char=40, score=0.30),\n",
        "    NEREntity(text=\"type\",          label=\"DIAGNOSIS\", start_char=41, end_char=45, score=0.25),\n",
        "    NEREntity(text=\"2 diabetes mellitus\", label=\"DIAGNOSIS\", start_char=46, end_char=65, score=0.91),\n",
        "]\n",
        "\n",
        "print(f\"Before post-processing ({len(raw_entities)} entities):\")\n",
        "for e in raw_entities:\n",
        "    print(f\"  '{e.text}' [{e.label}] score={e.score:.2f}\")\n",
        "\n",
        "cleaned = post_process_entities(raw_entities, text)\n",
        "print(f\"\\nAfter post-processing ({len(cleaned)} entities):\")\n",
        "for e in cleaned:\n",
        "    print(f\"  '{e.text}' [{e.label}] score={e.score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL01VOnkrTKm"
      },
      "source": [
        "---\n",
        "## 7. Evaluation Metrics — `compute_ner_metrics()`\n",
        "\n",
        "Entity-level precision, recall, and F1 using seqeval (or built-in fallback)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "sM2fdJedrTKm",
        "outputId": "0f14b4ae-a582-4192-dcda-dc730fd5fb8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:src.evaluation.metrics:seqeval not installed; using built-in entity-level metrics.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "compute_ner_metrics() missing 1 required positional argument: 'labels'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1399268134.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m metrics = compute_ner_metrics(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mFakePreds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlabel_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: compute_ner_metrics() missing 1 required positional argument: 'labels'"
          ]
        }
      ],
      "source": [
        "from src.evaluation.metrics import compute_ner_metrics, _extract_entities_from_bio\n",
        "import numpy as np\n",
        "\n",
        "# --- Simulated model predictions ---\n",
        "# Label mapping: 0=O, 1=B-DIAGNOSIS, 2=I-DIAGNOSIS\n",
        "label_list = [\"O\", \"B-DIAGNOSIS\", \"I-DIAGNOSIS\"]\n",
        "\n",
        "# Gold:  \"The patient has [congestive heart failure] and [diabetes].\"\n",
        "# Pred:  \"The patient has [congestive heart] failure and [diabetes].\"\n",
        "#  (boundary error on first entity, correct on second)\n",
        "\n",
        "gold_labels = [0, 0, 0, 1, 2, 2, 0, 1, 0]  # O O O B I I O B O\n",
        "pred_labels = [0, 0, 0, 1, 2, 0, 0, 1, 0]  # O O O B I O O B O (missed I on \"failure\")\n",
        "\n",
        "# compute_ner_metrics expects a namedtuple-like object with predictions and label_ids\n",
        "class FakePreds:\n",
        "    def __init__(self, preds, labels):\n",
        "        self.predictions = np.array([preds])\n",
        "        self.label_ids = np.array([labels])\n",
        "\n",
        "metrics = compute_ner_metrics(\n",
        "    FakePreds(pred_labels, gold_labels),\n",
        "    label_list=label_list,\n",
        ")\n",
        "\n",
        "print(\"=== Entity-Level Metrics ===\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "print(\"\\n(Note: boundary error on 'congestive heart failure' causes lower recall)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-KfXI_drTKm"
      },
      "outputs": [],
      "source": [
        "# --- BIO entity extraction utility ---\n",
        "labels = [\"O\", \"B-DIAGNOSIS\", \"I-DIAGNOSIS\", \"I-DIAGNOSIS\", \"O\", \"B-DIAGNOSIS\", \"O\"]\n",
        "entities = _extract_entities_from_bio(labels)\n",
        "print(\"Extracted entities from BIO sequence:\")\n",
        "for etype, start, end in sorted(entities):\n",
        "    print(f\"  {etype} @ tokens [{start}:{end}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC-VrusprTKn"
      },
      "source": [
        "---\n",
        "## 8. Curated ICD Dataset — Template-Generated Examples\n",
        "\n",
        "The `icd_ner` dataset includes ~100 template-generated sentences targeting common NER failure patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J7sJB-vrTKn"
      },
      "outputs": [],
      "source": [
        "from src.data.icd_dataset import _generate_template_examples, ICD_NER_LABELS\n",
        "\n",
        "print(f\"Label scheme: {ICD_NER_LABELS}\\n\")\n",
        "\n",
        "examples = _generate_template_examples()\n",
        "print(f\"Generated {len(examples)} template examples\\n\")\n",
        "\n",
        "# Show a few examples\n",
        "print(\"=== Sample Template Examples ===\")\n",
        "for ex in examples[:8]:\n",
        "    tokens = ex[\"tokens\"]\n",
        "    labels = ex[\"ner_labels\"]\n",
        "    # Reconstruct text with labels\n",
        "    labeled = []\n",
        "    for tok, lab in zip(tokens, labels):\n",
        "        if lab.startswith(\"B-\"):\n",
        "            labeled.append(f\"[{tok}\")\n",
        "        elif lab.startswith(\"I-\"):\n",
        "            labeled.append(tok)\n",
        "        else:\n",
        "            if labeled and labeled[-1] and not labeled[-1].endswith(\"]\"):\n",
        "                # Close the previous entity bracket\n",
        "                labeled[-1] = labeled[-1] + \"]\"\n",
        "            labeled.append(tok)\n",
        "    # Close any trailing entity\n",
        "    text = \" \".join(labeled)\n",
        "    if text.count(\"[\") > text.count(\"]\"):\n",
        "        text += \"]\"\n",
        "    print(f\"  {text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 9. MedMentions & MACCROBAT — Optional Dataset Sources\n",
        "\n",
        "The `icd_ner` composite dataset includes two optional HuggingFace sources that download on first use:\n",
        "\n",
        "1. **MedMentions** (`bigbio/medmentions`) — up to 5K examples from 4,392 PubMed abstracts with 350K+ UMLS entity mentions, filtered for disease/disorder semantic types (T047, T048, T019, T046, T191)\n",
        "2. **MACCROBAT** (`singh-aditya/MACCROBAT_biomedical_ner`) — up to 3K examples from 200 clinical case reports with DISEASE_DISORDER entities, providing clinical-note-style text that PubMed abstracts lack\n",
        "\n",
        "Both are loaded by `load_icd_ner_dataset()` as Sources 6 and 7. If the download fails, they are skipped gracefully."
      ],
      "metadata": {
        "id": "y5bgMUVmrTKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Source 6: MedMentions ---\n",
        "# Loads disease/disorder entities from 4,392 PubMed abstracts (bigbio/medmentions).\n",
        "# Filters for UMLS semantic types: T047 (Disease), T048 (Mental Disorder),\n",
        "# T019 (Congenital Abnormality), T046 (Pathologic Function), T191 (Neoplastic Process).\n",
        "\n",
        "from src.data.icd_dataset import _load_medmentions_diseases, _MEDMENTIONS_DISEASE_TYPES\n",
        "\n",
        "print(\"=== MedMentions Disease Loader ===\")\n",
        "print(f\"Target UMLS semantic types: {sorted(_MEDMENTIONS_DISEASE_TYPES)}\")\n",
        "print()\n",
        "\n",
        "try:\n",
        "    mm_dataset = _load_medmentions_diseases(max_examples=50)  # small sample for demo\n",
        "    for split, ds in mm_dataset.items():\n",
        "        n_entities = sum(1 for ex in ds for lab in ex[\"ner_labels\"] if lab.startswith(\"B-\"))\n",
        "        print(f\"  {split:12s}: {len(ds):4d} examples, {n_entities} DIAGNOSIS entities\")\n",
        "\n",
        "    # Show a few examples\n",
        "    print(\"\\nSample MedMentions examples:\")\n",
        "    for ex in list(mm_dataset[\"train\"])[:3]:\n",
        "        tokens = ex[\"tokens\"]\n",
        "        labels = ex[\"ner_labels\"]\n",
        "        # Show only the diagnosis spans\n",
        "        spans = []\n",
        "        current = []\n",
        "        for tok, lab in zip(tokens, labels):\n",
        "            if lab.startswith(\"B-\"):\n",
        "                if current:\n",
        "                    spans.append(\" \".join(current))\n",
        "                current = [tok]\n",
        "            elif lab.startswith(\"I-\") and current:\n",
        "                current.append(tok)\n",
        "            else:\n",
        "                if current:\n",
        "                    spans.append(\" \".join(current))\n",
        "                    current = []\n",
        "        if current:\n",
        "            spans.append(\" \".join(current))\n",
        "        text_preview = \" \".join(tokens[:15])\n",
        "        if len(tokens) > 15:\n",
        "            text_preview += \" ...\"\n",
        "        print(f\"  Text: {text_preview}\")\n",
        "        print(f\"  Entities: {spans}\")\n",
        "        print()\n",
        "except Exception as e:\n",
        "    print(f\"  MedMentions not available (expected in offline mode): {type(e).__name__}: {e}\")\n",
        "    print(\"  This source is optional — load_icd_ner_dataset() skips it gracefully.\")"
      ],
      "metadata": {
        "id": "wo_iQwxFrTKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQfsBCEPrTKn"
      },
      "outputs": [],
      "source": [
        "# --- Source 7: MACCROBAT ---\n",
        "# Loads DISEASE_DISORDER entities from 200 clinical case reports\n",
        "# (singh-aditya/MACCROBAT_biomedical_ner). Provides clinical-note-style text\n",
        "# that PubMed abstracts lack, closing the domain gap.\n",
        "\n",
        "from src.data.icd_dataset import _load_maccrobat_diseases, _MACCROBAT_DISEASE_LABELS\n",
        "\n",
        "print(\"=== MACCROBAT Disease Loader ===\")\n",
        "print(f\"Target entity labels: {sorted(_MACCROBAT_DISEASE_LABELS)}\")\n",
        "print()\n",
        "\n",
        "try:\n",
        "    mac_dataset = _load_maccrobat_diseases(max_examples=50)  # small sample for demo\n",
        "    for split, ds in mac_dataset.items():\n",
        "        n_entities = sum(1 for ex in ds for lab in ex[\"ner_labels\"] if lab.startswith(\"B-\"))\n",
        "        print(f\"  {split:12s}: {len(ds):4d} examples, {n_entities} DIAGNOSIS entities\")\n",
        "\n",
        "    # Show a few examples\n",
        "    print(\"\\nSample MACCROBAT examples:\")\n",
        "    for ex in list(mac_dataset[\"train\"])[:3]:\n",
        "        tokens = ex[\"tokens\"]\n",
        "        labels = ex[\"ner_labels\"]\n",
        "        # Show only the diagnosis spans\n",
        "        spans = []\n",
        "        current = []\n",
        "        for tok, lab in zip(tokens, labels):\n",
        "            if lab.startswith(\"B-\"):\n",
        "                if current:\n",
        "                    spans.append(\" \".join(current))\n",
        "                current = [tok]\n",
        "            elif lab.startswith(\"I-\") and current:\n",
        "                current.append(tok)\n",
        "            else:\n",
        "                if current:\n",
        "                    spans.append(\" \".join(current))\n",
        "                    current = []\n",
        "        if current:\n",
        "            spans.append(\" \".join(current))\n",
        "        text_preview = \" \".join(tokens[:15])\n",
        "        if len(tokens) > 15:\n",
        "            text_preview += \" ...\"\n",
        "        print(f\"  Text: {text_preview}\")\n",
        "        print(f\"  Entities: {spans}\")\n",
        "        print()\n",
        "except Exception as e:\n",
        "    print(f\"  MACCROBAT not available (expected in offline mode): {type(e).__name__}: {e}\")\n",
        "    print(\"  This source is optional — load_icd_ner_dataset() skips it gracefully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvrFJkOzrTKn"
      },
      "source": [
        "---\n",
        "## 10. End-to-End Pipeline — `MedicalCodingPipeline`\n",
        "\n",
        "Chains shorthand expansion → negation detection → ICD resolution → DRG cost estimation.\n",
        "\n",
        "Using `process_with_entities()` to supply pre-extracted entities (no NER model required)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXrXXYPprTKq",
        "outputId": "387f66a8-7edc-4d25-bc02-7a24f83092a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:src.clinical.shorthand:No CSV file found in Zenodo record 4567594.\n",
            "`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'atta00/icd10-codes' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "ERROR:datasets.load:`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'atta00/icd10-codes' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline initialized:\n",
            "  Shorthand expander: True\n",
            "  Negation detector:  True\n",
            "  ICD lookup:         True\n",
            "  DRG estimator:      False\n"
          ]
        }
      ],
      "source": [
        "from src.clinical.pipeline import MedicalCodingPipeline, MedicalEntity\n",
        "\n",
        "# Initialize pipeline without a trained NER model\n",
        "pipeline = MedicalCodingPipeline(\n",
        "    model_path=None,         # No NER model — we'll supply entities manually\n",
        "    expand_shorthand=True,\n",
        "    detect_negation=True,\n",
        "    negation_strategy=\"rules\",\n",
        "    resolve_icd_codes=True,\n",
        "    icd_top_k=3,\n",
        "    resolve_drg=False,       # Set True if drgpy is installed\n",
        ")\n",
        "\n",
        "print(\"Pipeline initialized:\")\n",
        "print(f\"  Shorthand expander: {pipeline.shorthand_expander is not None}\")\n",
        "print(f\"  Negation detector:  {pipeline.negation_detector is not None}\")\n",
        "print(f\"  ICD lookup:         {pipeline.icd_lookup is not None}\")\n",
        "print(f\"  DRG estimator:      {pipeline.drg_estimator is not None}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1dcAwBlrTKq",
        "outputId": "75623a7d-0fd1-4563-b7ae-b51db2b813b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  Patient denies chest pain. Diagnosed with congestive heart failure and hypertension.\n",
            "\n",
            "=== Pipeline Results ===\n",
            "  Entity: chest pain\n",
            "    Label:    DIAGNOSIS\n",
            "    Negation: negated (trigger: denies)\n",
            "    Score:    0.950\n",
            "\n",
            "  Entity: congestive heart failure\n",
            "    Label:    DIAGNOSIS\n",
            "    Negation: affirmed (trigger: none)\n",
            "    Score:    0.970\n",
            "\n",
            "  Entity: hypertension\n",
            "    Label:    DIAGNOSIS\n",
            "    Negation: affirmed (trigger: none)\n",
            "    Score:    0.960\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Process pre-extracted entities ---\n",
        "clinical_text = \"Patient denies chest pain. Diagnosed with congestive heart failure and hypertension.\"\n",
        "\n",
        "pre_extracted = [\n",
        "    {\"text\": \"chest pain\",              \"label\": \"DIAGNOSIS\", \"start\": 15, \"end\": 25, \"score\": 0.95},\n",
        "    {\"text\": \"congestive heart failure\", \"label\": \"DIAGNOSIS\", \"start\": 43, \"end\": 66, \"score\": 0.97},\n",
        "    {\"text\": \"hypertension\",            \"label\": \"DIAGNOSIS\", \"start\": 71, \"end\": 83, \"score\": 0.96},\n",
        "]\n",
        "\n",
        "results = pipeline.process_with_entities(clinical_text, pre_extracted)\n",
        "\n",
        "print(f\"Input:  {clinical_text}\\n\")\n",
        "print(\"=== Pipeline Results ===\")\n",
        "for ent in results:\n",
        "    print(f\"  Entity: {ent.text}\")\n",
        "    print(f\"    Label:    {ent.label}\")\n",
        "    print(f\"    Negation: {ent.negation} (trigger: {ent.negation_trigger or 'none'})\")\n",
        "    print(f\"    Score:    {ent.score:.3f}\")\n",
        "    if ent.icd_codes:\n",
        "        print(f\"    ICD codes:\")\n",
        "        for icd in ent.icd_codes[:2]:\n",
        "            print(f\"      {icd['code']}: {icd['description']} (score={icd['score']:.3f})\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ6JoxbxrTKq",
        "outputId": "ad6685de-5e1e-4e14-b3f3-1ed0395d0020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient denies chest pain. Diagnosed with congestive heart failure and hypertension.\n",
            "\n",
            "  [chest pain](DIAGNOSIS, NEGATED, trigger=\"denies\", score=0.950)\n",
            "  [congestive heart failure](DIAGNOSIS, AFFIRMED, score=0.970)\n",
            "  [hypertension](DIAGNOSIS, AFFIRMED, score=0.960)\n"
          ]
        }
      ],
      "source": [
        "# --- Human-readable formatted output ---\n",
        "formatted = pipeline.format_output(clinical_text, results)\n",
        "print(formatted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQI2vLWhrTKq",
        "outputId": "ba422d68-87c2-426c-8057-72ecbda6a27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  chest pain                     is_affirmed=False  is_negated=True\n",
            "  congestive heart failure       is_affirmed=True  is_negated=False\n",
            "  hypertension                   is_affirmed=True  is_negated=False\n",
            "\n",
            "=== JSON serialization ===\n",
            "{\n",
            "  \"text\": \"chest pain\",\n",
            "  \"label\": \"DIAGNOSIS\",\n",
            "  \"start\": 15,\n",
            "  \"end\": 25,\n",
            "  \"score\": 0.95,\n",
            "  \"negation\": \"negated\",\n",
            "  \"negation_trigger\": \"denies\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# --- MedicalEntity properties and serialization ---\n",
        "for ent in results:\n",
        "    print(f\"  {ent.text:30s} is_affirmed={ent.is_affirmed}  is_negated={ent.is_negated}\")\n",
        "\n",
        "print(\"\\n=== JSON serialization ===\")\n",
        "import json\n",
        "print(json.dumps(results[0].to_dict(), indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_cEGJCZrTKr",
        "outputId": "b715a416-5ae8-4eba-bff1-f08be9f03f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Multiple Clinical Scenarios ===\n",
            "\n",
            "No evidence of pneumonia on chest X-ray. Patient has COPD exacerbation.\n",
            "  [pneumonia] NEGATED      ICD=N/A\n",
            "  [COPD exacerbation] AFFIRMED     ICD=N/A\n",
            "\n",
            "History of stroke. Currently presents with acute kidney injury.\n",
            "  [stroke] HISTORICAL   ICD=N/A\n",
            "  [acute kidney injury] AFFIRMED     ICD=N/A\n",
            "\n",
            "Mother had breast cancer. Patient denies any malignancy.\n",
            "  [breast cancer] FAMILY       ICD=N/A\n",
            "  [malignancy] NEGATED      ICD=N/A\n"
          ]
        }
      ],
      "source": [
        "# --- Multiple clinical scenarios ---\n",
        "scenarios = [\n",
        "    (\n",
        "        \"No evidence of pneumonia on chest X-ray. Patient has COPD exacerbation.\",\n",
        "        [\n",
        "            {\"text\": \"pneumonia\",         \"label\": \"DIAGNOSIS\", \"start\": 15, \"end\": 24, \"score\": 0.92},\n",
        "            {\"text\": \"COPD exacerbation\", \"label\": \"DIAGNOSIS\", \"start\": 43, \"end\": 60, \"score\": 0.94},\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"History of stroke. Currently presents with acute kidney injury.\",\n",
        "        [\n",
        "            {\"text\": \"stroke\",             \"label\": \"DIAGNOSIS\", \"start\": 11, \"end\": 17, \"score\": 0.90},\n",
        "            {\"text\": \"acute kidney injury\", \"label\": \"DIAGNOSIS\", \"start\": 43, \"end\": 61, \"score\": 0.96},\n",
        "        ]\n",
        "    ),\n",
        "    (\n",
        "        \"Mother had breast cancer. Patient denies any malignancy.\",\n",
        "        [\n",
        "            {\"text\": \"breast cancer\", \"label\": \"DIAGNOSIS\", \"start\": 11, \"end\": 24, \"score\": 0.93},\n",
        "            {\"text\": \"malignancy\",   \"label\": \"DIAGNOSIS\", \"start\": 45, \"end\": 55, \"score\": 0.88},\n",
        "        ]\n",
        "    ),\n",
        "]\n",
        "\n",
        "print(\"=== Multiple Clinical Scenarios ===\")\n",
        "for text, ents in scenarios:\n",
        "    results = pipeline.process_with_entities(text, ents)\n",
        "    print(f\"\\n{text}\")\n",
        "    for r in results:\n",
        "        icd = r.icd_codes[0]['code'] if r.icd_codes else 'N/A'\n",
        "        print(f\"  [{r.text}] {r.negation.upper():12s} ICD={icd}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esTDy2wkrTKr"
      },
      "source": [
        "---\n",
        "## 11. Adversarial Training — `FGM`, `PGD`, `AdversarialTrainer`\n",
        "\n",
        "FGM and PGD perturb word embeddings during training to improve robustness (+0.5-1.5% F1).\n",
        "\n",
        "This section demonstrates the API structure. Actual training requires a GPU and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWs3lANMrTKr",
        "outputId": "e9248517-8f7c-4e23-f432-2a18afdad811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGM perturbation L2 norm: 1.0000\n",
            "Embeddings restored: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from src.training.adversarial import FGM, PGD, AdversarialTrainer\n",
        "\n",
        "# --- Demonstrate FGM on a toy model ---\n",
        "class ToyModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.word_embeddings = torch.nn.Embedding(100, 16)\n",
        "        self.classifier = torch.nn.Linear(16, 3)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        emb = self.word_embeddings(input_ids)\n",
        "        return self.classifier(emb.mean(dim=1))\n",
        "\n",
        "model = ToyModel()\n",
        "\n",
        "# Simulate a forward + backward pass\n",
        "input_ids = torch.randint(0, 100, (2, 5))\n",
        "output = model(input_ids)\n",
        "loss = output.sum()\n",
        "loss.backward()\n",
        "\n",
        "# --- FGM attack ---\n",
        "fgm = FGM(model, epsilon=1.0)\n",
        "original_emb = model.word_embeddings.weight.data.clone()\n",
        "\n",
        "fgm.attack()\n",
        "perturbed_emb = model.word_embeddings.weight.data.clone()\n",
        "perturbation_norm = torch.norm(perturbed_emb - original_emb).item()\n",
        "print(f\"FGM perturbation L2 norm: {perturbation_norm:.4f}\")\n",
        "\n",
        "fgm.restore()\n",
        "restored_emb = model.word_embeddings.weight.data.clone()\n",
        "print(f\"Embeddings restored: {torch.allclose(original_emb, restored_emb)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHs7z1x8rTKr",
        "outputId": "306da051-b6e6-4332-a0ae-4437d6c6fa6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  PGD step 1: perturbation L2 norm = 0.1000\n",
            "  PGD step 2: perturbation L2 norm = 0.2000\n",
            "  PGD step 3: perturbation L2 norm = 0.3000\n",
            "Embeddings restored: True\n"
          ]
        }
      ],
      "source": [
        "# --- PGD multi-step attack ---\n",
        "model.zero_grad()\n",
        "output = model(input_ids)\n",
        "loss = output.sum()\n",
        "loss.backward()\n",
        "\n",
        "pgd = PGD(model, epsilon=0.3, alpha=0.1, num_steps=3)\n",
        "original_emb = model.word_embeddings.weight.data.clone()\n",
        "\n",
        "pgd.save()\n",
        "for step in range(pgd.num_steps):\n",
        "    pgd.attack_step()\n",
        "    step_emb = model.word_embeddings.weight.data.clone()\n",
        "    step_norm = torch.norm(step_emb - original_emb).item()\n",
        "    print(f\"  PGD step {step+1}: perturbation L2 norm = {step_norm:.4f}\")\n",
        "\n",
        "pgd.restore()\n",
        "print(f\"Embeddings restored: {torch.allclose(original_emb, model.word_embeddings.weight.data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZIbYAt6rTKr",
        "outputId": "8d6f64c8-db28-4cde-baf5-b26350c2497d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdversarialTrainer extends HuggingFace Trainer with:\n",
            "  - Automatic FGM or PGD perturbation during training_step()\n",
            "  - Clean loss + adversarial loss combined\n",
            "  - No architecture changes required\n",
            "\n",
            "Usage:\n",
            "  trainer = AdversarialTrainer(\n",
            "      model=model, args=training_args,\n",
            "      train_dataset=train_ds, eval_dataset=eval_ds,\n",
            "      adv_method='fgm', adv_epsilon=1.0,\n",
            "  )\n",
            "  trainer.train()\n",
            "\n",
            "CLI:\n",
            "  python scripts/train.py --model pubmedbert --dataset icd_ner --adversarial\n",
            "  python scripts/train.py --model pubmedbert --dataset icd_ner --adversarial --adv-method pgd\n"
          ]
        }
      ],
      "source": [
        "# --- AdversarialTrainer overview ---\n",
        "print(\"AdversarialTrainer extends HuggingFace Trainer with:\")\n",
        "print(\"  - Automatic FGM or PGD perturbation during training_step()\")\n",
        "print(\"  - Clean loss + adversarial loss combined\")\n",
        "print(\"  - No architecture changes required\")\n",
        "print()\n",
        "print(\"Usage:\")\n",
        "print(\"  trainer = AdversarialTrainer(\")\n",
        "print(\"      model=model, args=training_args,\")\n",
        "print(\"      train_dataset=train_ds, eval_dataset=eval_ds,\")\n",
        "print(\"      adv_method='fgm', adv_epsilon=1.0,\")\n",
        "print(\"  )\")\n",
        "print(\"  trainer.train()\")\n",
        "print()\n",
        "print(\"CLI:\")\n",
        "print(\"  python scripts/train.py --model pubmedbert --dataset icd_ner --adversarial\")\n",
        "print(\"  python scripts/train.py --model pubmedbert --dataset icd_ner --adversarial --adv-method pgd\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JycT4AbfrTKr"
      },
      "source": [
        "---\n",
        "## 12. Assertion Classifier (Transformer-based) — Overview\n",
        "\n",
        "The `AssertionClassifier` uses `bvanaken/clinical-assertion-negation-bert` for learned assertion detection.\n",
        "It downloads the model on first use (~440MB), so we show the API without executing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7RGx1QTrTKr",
        "outputId": "ca066ccc-bb9a-48d7-a8a8-61b96d31bf55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AssertionClassifier API:\n",
            "  .predict(text, entity_text, entity_start, entity_end) → Dict\n",
            "    Returns: {'label': 'PRESENT'|'ABSENT'|'POSSIBLE', 'negation': ..., 'score': float}\n",
            "\n",
            "  .annotate_entities(text, entities) → List[Dict]\n",
            "    Adds: 'negation', 'assertion_label', 'assertion_score' to each entity\n",
            "\n",
            "Pipeline integration:\n",
            "  pipeline = MedicalCodingPipeline(negation_strategy='transformer')\n"
          ]
        }
      ],
      "source": [
        "# To actually run: uncomment the lines below (requires model download)\n",
        "#\n",
        "# from src.clinical.assertion import AssertionClassifier\n",
        "#\n",
        "# classifier = AssertionClassifier(device=\"cpu\")\n",
        "#\n",
        "# result = classifier.predict(\n",
        "#     text=\"Patient denies any chest pain or shortness of breath.\",\n",
        "#     entity_text=\"chest pain\",\n",
        "#     entity_start=19,\n",
        "#     entity_end=29,\n",
        "# )\n",
        "# print(result)  # {'label': 'ABSENT', 'negation': 'negated', 'score': 0.97}\n",
        "#\n",
        "# # Batch annotation:\n",
        "# entities = [\n",
        "#     {\"text\": \"chest pain\", \"label\": \"DIAGNOSIS\", \"start\": 19, \"end\": 29},\n",
        "# ]\n",
        "# annotated = classifier.annotate_entities(\n",
        "#     \"Patient denies any chest pain.\", entities\n",
        "# )\n",
        "\n",
        "print(\"AssertionClassifier API:\")\n",
        "print(\"  .predict(text, entity_text, entity_start, entity_end) → Dict\")\n",
        "print(\"    Returns: {'label': 'PRESENT'|'ABSENT'|'POSSIBLE', 'negation': ..., 'score': float}\")\n",
        "print()\n",
        "print(\"  .annotate_entities(text, entities) → List[Dict]\")\n",
        "print(\"    Adds: 'negation', 'assertion_label', 'assertion_score' to each entity\")\n",
        "print()\n",
        "print(\"Pipeline integration:\")\n",
        "print(\"  pipeline = MedicalCodingPipeline(negation_strategy='transformer')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48x5hcH0rTKr"
      },
      "source": [
        "---\n",
        "## 13. CLI Scripts Reference\n",
        "\n",
        "Quick reference for the training, prediction, evaluation, and benchmark scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlF9qjxFrTKr",
        "outputId": "be3f863e-8cf5-4e48-e88f-ff875b433617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training ===\n",
            "  python scripts/train.py --model pubmedbert --dataset icd_ner\n",
            "  python scripts/train.py --model pubmedbert --dataset icd_ner --adversarial\n",
            "  python scripts/train.py --model pubmedbert --dataset icd_ner --adversarial --adv-method pgd\n",
            "  python scripts/train.py --model bio_clinicalbert --dataset icd_ner --use-crf --lr 3e-5\n",
            "\n",
            "=== Prediction ===\n",
            "  python scripts/predict.py --model-path outputs/pubmedbert_icd_ner/best_model --text \"Pt denies cp.\"\n",
            "  python scripts/predict.py --model-path outputs/pubmedbert_icd_ner/best_model --icd-codes\n",
            "  python scripts/predict.py --model-path outputs/pubmedbert_icd_ner/best_model --input-file data.txt --output-file out.json\n",
            "\n",
            "=== Evaluation ===\n",
            "  python scripts/evaluate.py --model-path outputs/pubmedbert_icd_ner/best_model --dataset icd_ner\n",
            "  python scripts/evaluate.py --model-path outputs/pubmedbert_icd_ner/best_model --dataset icd_ner --error-analysis\n",
            "\n",
            "=== Benchmark ===\n",
            "  python scripts/benchmark.py --models pubmedbert biobert bio_clinicalbert --datasets icd_ner ncbi_disease bc5cdr\n",
            "\n",
            "=== Tests ===\n",
            "  python -m pytest tests/ -v\n",
            "  python -m pytest tests/ --cov=src --cov-report=term-missing\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cli_reference = \"\"\"\n",
        "=== Training ===\n",
        "  python scripts/train.py --model pubmedbert --dataset icd_ner\n",
        "  python scripts/train.py --model pubmedbert --dataset icd_ner --adversarial\n",
        "  python scripts/train.py --model pubmedbert --dataset icd_ner --adversarial --adv-method pgd\n",
        "  python scripts/train.py --model bio_clinicalbert --dataset icd_ner --use-crf --lr 3e-5\n",
        "\n",
        "=== Prediction ===\n",
        "  python scripts/predict.py --model-path outputs/pubmedbert_icd_ner/best_model --text \"Pt denies cp.\"\n",
        "  python scripts/predict.py --model-path outputs/pubmedbert_icd_ner/best_model --icd-codes\n",
        "  python scripts/predict.py --model-path outputs/pubmedbert_icd_ner/best_model --input-file data.txt --output-file out.json\n",
        "\n",
        "=== Evaluation ===\n",
        "  python scripts/evaluate.py --model-path outputs/pubmedbert_icd_ner/best_model --dataset icd_ner\n",
        "  python scripts/evaluate.py --model-path outputs/pubmedbert_icd_ner/best_model --dataset icd_ner --error-analysis\n",
        "\n",
        "=== Benchmark ===\n",
        "  python scripts/benchmark.py --models pubmedbert biobert bio_clinicalbert --datasets icd_ner ncbi_disease bc5cdr\n",
        "\n",
        "=== Tests ===\n",
        "  python -m pytest tests/ -v\n",
        "  python -m pytest tests/ --cov=src --cov-report=term-missing\n",
        "\"\"\"\n",
        "print(cli_reference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fftzMMVlrTKr"
      },
      "source": [
        "---\n",
        "## 14. Running the Test Suite\n",
        "\n",
        "All tests use mocked models and fallback data — no GPU or network access required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzWQr3KGrTKr",
        "outputId": "4e766be9-e456-47be-b96c-b621744f67cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To run tests from the command line:\n",
            "  cd /content/Medical_Code_Intelligence\n",
            "  python -m pytest tests/ -v\n",
            "\n",
            "Key test files:\n",
            "  test_negation.py                    — Rule-based negation detection (200+ assertions)\n",
            "  test_assertion.py                   — Transformer assertion classifier\n",
            "  test_icd_ner_dataset.py             — Composite dataset loading + garbage label cleaning\n",
            "  test_pipeline.py                    — End-to-end pipeline integration\n",
            "  test_icd_pipeline.py                — ICD code resolution pipeline\n",
            "  test_shorthand.py                   — Abbreviation expansion\n",
            "  test_disambiguation.py              — Abbreviation disambiguation\n",
            "  test_preprocessing.py               — Tokenization and label alignment\n",
            "  test_entity_postprocessing.py       — Entity filtering and merging\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to run the full test suite from this notebook:\n",
        "# !cd {REPO_ROOT} && python -m pytest tests/ -v --tb=short 2>&1 | tail -30\n",
        "\n",
        "print(\"To run tests from the command line:\")\n",
        "print(f\"  cd {REPO_ROOT}\")\n",
        "print(\"  python -m pytest tests/ -v\")\n",
        "print()\n",
        "print(\"Key test files:\")\n",
        "test_files = [\n",
        "    (\"test_negation.py\",            \"Rule-based negation detection (200+ assertions)\"),\n",
        "    (\"test_assertion.py\",           \"Transformer assertion classifier\"),\n",
        "    (\"test_icd_ner_dataset.py\",     \"Composite dataset loading + garbage label cleaning\"),\n",
        "    (\"test_pipeline.py\",            \"End-to-end pipeline integration\"),\n",
        "    (\"test_icd_pipeline.py\",        \"ICD code resolution pipeline\"),\n",
        "    (\"test_shorthand.py\",           \"Abbreviation expansion\"),\n",
        "    (\"test_disambiguation.py\",      \"Abbreviation disambiguation\"),\n",
        "    (\"test_preprocessing.py\",       \"Tokenization and label alignment\"),\n",
        "    (\"test_entity_postprocessing.py\", \"Entity filtering and merging\"),\n",
        "]\n",
        "for filename, desc in test_files:\n",
        "    print(f\"  {filename:35s} — {desc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_QbAkzHrTKr"
      },
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrated the full Medical Code Intelligence pipeline:\n",
        "\n",
        "```\n",
        "Clinical Text\n",
        "  → ShorthandExpander (abbreviation expansion with offset tracking)\n",
        "  → NER Model (transformer token classification, BIO scheme)\n",
        "  → post_process_entities() (stopword filter, fragment merging)\n",
        "  → NegationDetector or AssertionClassifier (6 assertion statuses)\n",
        "  → ICDCodeLookup (TF-IDF matching against 51K codes)\n",
        "  → DRGCostEstimator (ICD-10 → MS-DRG → cost estimate)\n",
        "  → MedicalEntity list (text, label, negation, ICD codes, DRG info)\n",
        "```\n",
        "\n",
        "Every component has offline fallback data so this notebook runs on CPU without network access."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b2bb1af86859472192d2a48dfff41cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad4b1fdf34064ce5b784a7a5fd31026c",
              "IPY_MODEL_e45c343c84cf4870ab1feb5e0ff3c915",
              "IPY_MODEL_184d01fbffd94b18813c9ffbd9db380c"
            ],
            "layout": "IPY_MODEL_04d5beae2702474e819f28e237d0eb7f"
          }
        },
        "d447f607fb0e49ec89900f977b203e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb897841b5b74a9ebf312d247ef111dc",
              "IPY_MODEL_3653a0e98823483ab77a5578f78754a0",
              "IPY_MODEL_b7dfc7b7665c4ea7a1607b3ff0f2bc93"
            ],
            "layout": "IPY_MODEL_c5c2927e99944dbd8b5e6fcceaf48353"
          }
        },
        "08785f05ee4f478eb209d3082db2ddf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa31f73f700c45abb7f4b1c8f209e243",
              "IPY_MODEL_0ae34427ddec4b9ca1eadc0b28421d8f",
              "IPY_MODEL_6686fc5ea89e4495b2ac68a7382bd99e"
            ],
            "layout": "IPY_MODEL_c8241b7f903a486dba60cde03195d890"
          }
        },
        "8f57145a794c4f108d1683773ba283b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ea1c79a914b4df999c04bbfc27e3b52",
              "IPY_MODEL_66014cabef1e452da37e81c14c9fc5d3",
              "IPY_MODEL_7c52c69b35d649e0a3d6c09a57043569"
            ],
            "layout": "IPY_MODEL_8cef62aff6424e728c72e4c82e4345e9"
          }
        },
        "034bc68b896b4c579530bbdae870c761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dffd37389c9e4e69b97a13c090653576",
              "IPY_MODEL_b73b271fb8524d19a1d21b916da47df1",
              "IPY_MODEL_7e5af55bc56b4cdbaab4e720f430ae22"
            ],
            "layout": "IPY_MODEL_a71fc53932e24efab861af0a41412b11"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}